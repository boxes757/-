import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('01-linear regression/ex1data2.txt',names=['size','room','price'])
print(data.head())

def standard(data):
    return (data-data.mean()) / data.std()
data = standard(data)
print(data.head())

data.insert(0,'ones',1)
print(data.head())

X = data.iloc[:,0:-1]
Y = data.iloc[:,-1]
print(X.head())
print(Y.head())

X = X.values
Y = Y.values
print(X.shape)
Y = Y.reshape(47,1)
print(Y.shape)

def CostFunction(X,Y,theta):
    inner = np.power((X @ theta - Y),2)
    return np.sum(inner)/ (2 * len(X))

theta = np.zeros((3,1))
print(theta)

cost_init = CostFunction(X,Y,theta)
print(cost_init)

def GradientDescent(X,Y,theta,alpha,times,isprint = False):
    costs=[]
    for i in range(times):
        theta = theta - (X.T @ (X @ theta - Y)) * (alpha / len(X))
        cost = CostFunction(X,Y,theta)
        costs.append(cost)
        if(i%500 == 0):
            if(isprint):
                print(cost)
    return theta,costs


can_alpha=[0.01,0.02,0.001,0.003,0.0001]
times=2000

for alpha in can_alpha:
    isprint = True
    _,costs=GradientDescent(X,Y,theta,alpha,times,isprint)
    print('当前alpha值:',alpha)

isprint = False

flg,ax = plt.subplots()
for alpha in can_alpha:
    _,costs = GradientDescent(X,Y,theta,alpha,times,isprint)
    ax.plot(np.arange(times),costs,label=alpha)
ax.legend()
ax.set(xlabel='times',ylabel='price',title='times & price')
plt.savefig('01-linear regression/duo1.jpg')
plt.show()
